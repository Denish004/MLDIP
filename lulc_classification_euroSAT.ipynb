{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2180c19",
   "metadata": {},
   "source": [
    "# Import the essential libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e07f715",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'venv (Python 3.9.7)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '\"c:/Users/Sanskar Wakchaure/Desktop/ML_DIP/venv/Scripts/python.exe\" -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "# Essential and common packages\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Read and visualize the raster data\n",
    "import rasterio\n",
    "from rasterio.plot import show\n",
    "\n",
    "# Plots and bars\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Computation library\n",
    "import numpy as np\n",
    "\n",
    "# Tensorflow for building the resnet50 model\n",
    "import tensorflow.python.keras as k\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from tensorflow.keras.initializers import random_uniform, glorot_uniform\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Sklearn for confusion matrix\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# For visualization of plots without plt.show()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6df6d9",
   "metadata": {},
   "source": [
    "# Define the required variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_url = r'C:\\Users\\tek\\Desktop\\try\\DL-for-LULC-prediction\\EuroSAT\\2750'\n",
    "batch_size = 32\n",
    "img_height = 64\n",
    "img_width = 64\n",
    "validation_split=0.2\n",
    "rescale=1.0/255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edefdf9d",
   "metadata": {},
   "source": [
    "# Data preparation for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4902df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(validation_split=validation_split, rescale=rescale)\n",
    "dataset = tf.keras.preprocessing.image_dataset_from_directory(dataset_url, image_size=(img_height, img_width), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f535e97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataset = datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(img_height, img_width),\n",
    "                                           subset=\"training\",\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f208eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = datagen.flow_from_directory(batch_size=batch_size,\n",
    "                                           directory=dataset_url,\n",
    "                                           shuffle=True,\n",
    "                                           target_size=(img_height, img_width),\n",
    "                                           subset=\"validation\",\n",
    "                                           class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab76070a",
   "metadata": {},
   "source": [
    "# Visualization of input datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bdac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = dataset.class_names\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in dataset.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ac666",
   "metadata": {},
   "source": [
    "# ResNet50 Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc87f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identity_block(X, f, filters, training=True, initializer=random_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the identity block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to random uniform initializer\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the identity block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value.\n",
    "    X_shortcut = X\n",
    "    cache = []\n",
    "    # First component of main path\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training) # Default axis\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(filters = F2, kernel_size = (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(filters = F3, kernel_size = (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path, and pass it through a RELU activation (≈2 lines)\n",
    "    X = Add()([X_shortcut, X])\n",
    "    X = X = Activation('relu')(X, training = training)\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad8819e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_block(X, f, filters, s = 2, training=True, initializer=glorot_uniform):\n",
    "    \"\"\"\n",
    "    Implementation of the convolutional block as defined in Figure 4\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input tensor of shape (m, n_H_prev, n_W_prev, n_C_prev)\n",
    "    f -- integer, specifying the shape of the middle CONV's window for the main path\n",
    "    filters -- python list of integers, defining the number of filters in the CONV layers of the main path\n",
    "    s -- Integer, specifying the stride to be used\n",
    "    training -- True: Behave in training mode\n",
    "                False: Behave in inference mode\n",
    "    initializer -- to set up the initial weights of a layer. Equals to Glorot uniform initializer, \n",
    "                   also called Xavier uniform initializer.\n",
    "    \n",
    "    Returns:\n",
    "    X -- output of the convolutional block, tensor of shape (n_H, n_W, n_C)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Retrieve Filters\n",
    "    F1, F2, F3 = filters\n",
    "    \n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "\n",
    "\n",
    "    ##### MAIN PATH #####\n",
    "    \n",
    "    # First component of main path glorot_uniform(seed=0)\n",
    "    X = Conv2D(filters = F1, kernel_size = 1, strides = (s, s), padding='valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training=training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    \n",
    "    # Second component of main path (≈3 lines)\n",
    "    X = Conv2D(F2, (f, f), strides = (1, 1), padding = 'same', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # Third component of main path (≈2 lines)\n",
    "    X = Conv2D(F3, (1, 1), strides = (1, 1), padding = 'valid', kernel_initializer = initializer(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X, training = training)\n",
    "\n",
    "    ##### SHORTCUT PATH #### (≈2 lines)\n",
    "    X_shortcut = Conv2D(F3, (1, 1), strides = (s, s), padding = 'valid', kernel_initializer = initializer(seed=0))(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 3)(X_shortcut, training = training)\n",
    "\n",
    "    # Final step: Add shortcut value to main path (Use this order [X, X_shortcut]), and pass it through a RELU activation\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d013bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResNet50(input_shape = (64, 64, 3), classes = 6):\n",
    "    \"\"\"\n",
    "    Stage-wise implementation of the architecture of the popular ResNet50:\n",
    "    CONV2D -> BATCHNORM -> RELU -> MAXPOOL -> CONVBLOCK -> IDBLOCK*2 -> CONVBLOCK -> IDBLOCK*3\n",
    "    -> CONVBLOCK -> IDBLOCK*5 -> CONVBLOCK -> IDBLOCK*2 -> AVGPOOL -> FLATTEN -> DENSE \n",
    "\n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "    classes -- integer, number of classes\n",
    "\n",
    "    Returns:\n",
    "    model -- a Model() instance in Keras\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the input as a tensor with shape input_shape\n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    \n",
    "    # Zero-Padding\n",
    "    X = ZeroPadding2D((3, 3))(X_input)\n",
    "    \n",
    "    # Stage 1\n",
    "    X = Conv2D(64, (7, 7), strides = (2, 2), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = BatchNormalization(axis = 3)(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
    "\n",
    "    # Stage 2\n",
    "    X = convolutional_block(X, f = 3, filters = [64, 64, 256], s = 1)\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    X = identity_block(X, 3, [64, 64, 256])\n",
    "    \n",
    "   # Stage 3 (≈4 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [128, 128, 512], s = 2)\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "    X = identity_block(X, 3, [128, 128, 512])\n",
    "\n",
    "    # Stage 4 (≈6 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [256, 256, 1024], s = 2)\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "    X = identity_block(X, 3, [256, 256, 1024])\n",
    "\n",
    "    # Stage 5 (≈3 lines)\n",
    "    X = convolutional_block(X, f = 3, filters = [512, 512, 2048], s = 2)\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "    X = identity_block(X, 3, [512, 512, 2048])\n",
    "\n",
    "    # AVGPOOL (≈1 line). Use \"X = AveragePooling2D(...)(X)\"\n",
    "    X = AveragePooling2D(pool_size = (2, 2), name = 'avg_pool')(X)\n",
    "    \n",
    "\n",
    "    # output layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(classes, activation='softmax', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    \n",
    "    # Create model\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d50885",
   "metadata": {},
   "source": [
    "# Model train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1baf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(input_shape=(64,64,3), classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc912ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475d3df2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# please increase the epoch for higher accuracy (epochs=100)\n",
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acde0e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lulc_20_epoch')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f182331",
   "metadata": {},
   "source": [
    "# analyzing results and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73e4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16.53, 11.69))\n",
    "ax1.plot(history.history['accuracy'])\n",
    "ax1.plot(history.history['val_accuracy'])\n",
    "ax1.set_xlabel('epoch')\n",
    "ax1.set_ylabel('accuracy')\n",
    "ax1.set_title('Accuracy over epoch')\n",
    "ax1.legend(['Train', 'Test'], loc='upper left')\n",
    "\n",
    "ax2.plot(history.history['loss'])\n",
    "ax2.plot(history.history['val_loss'])\n",
    "ax2.set_xlabel('epoch')\n",
    "ax2.set_ylabel('loss')\n",
    "ax2.set_title('Loss over epoch')\n",
    "ax2.legend(['Train', 'Test'], loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c36c44cc",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9de6eb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for i, (image_batch, label_batch) in enumerate(test_dataset):   # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    preds = model.predict(image_batch)\n",
    "    # append predicted labels\n",
    "    y_pred.append(np.argmax(preds, axis =  1))\n",
    "    if i==300:\n",
    "        break\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "correct_labels = np.argmax(correct_labels, axis=1)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be581ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(correct_labels, predicted_labels)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0dc1681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        figsize=(10, 10),\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "            horizontalalignment=\"center\",\n",
    "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2cceca",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(cm, train_dataset.class_indices, cmap='Reds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa18a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.applications.ResNet101(\n",
    "#     include_top=False,\n",
    "#     input_tensor=None,\n",
    "#     input_shape=(64,64, 3),\n",
    "#     classes=10,\n",
    "# )\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d883fb83",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67618913",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(r\"lulc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c689b0",
   "metadata": {},
   "source": [
    "# Thank you "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
